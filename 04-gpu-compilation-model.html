

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>CUDA GPU Compilation Model &#8212; molssi_gpu_programming  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/design-tabs.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-FHKVGE8HKZ"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-FHKVGE8HKZ');
            </script>
    <script>DOCUMENTATION_OPTIONS.pagename = '04-gpu-compilation-model';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="CUDA Execution Model" href="05-cuda-execution-model.html" />
    <link rel="prev" title="CUDA Programming Model" href="03-cuda-program-model.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/molssi_main_logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/molssi_main_logo_inverted_white.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
    <p class="title logo__title">Fundamentals of GPU Programming</p>
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="setup.html">
                        Setup
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="01-introduction.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="02-basic-concepts.html">
                        Basic Concepts in CUDA Programming
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="03-cuda-program-model.html">
                        CUDA Programming Model
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        CUDA GPU Compilation Model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="05-cuda-execution-model.html">
                        CUDA Execution Model
                      </a>
                    </li>
                

                <li class="nav-item">
                  <a class="nav-link nav-external" href="https://molssi.org">
                    MolSSI
                  </a>
                </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/MolSSI-Education/gpu_programming_beginner" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/MolSSI_NSF" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="setup.html">
                        Setup
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="01-introduction.html">
                        Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="02-basic-concepts.html">
                        Basic Concepts in CUDA Programming
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="03-cuda-program-model.html">
                        CUDA Programming Model
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        CUDA GPU Compilation Model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="05-cuda-execution-model.html">
                        CUDA Execution Model
                      </a>
                    </li>
                

                <li class="nav-item">
                  <a class="nav-link nav-external" href="https://molssi.org">
                    MolSSI
                  </a>
                </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/MolSSI-Education/gpu_programming_beginner" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/MolSSI_NSF" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">CUDA GPU Compilation Model</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="cuda-gpu-compilation-model">
<h1>CUDA GPU Compilation Model<a class="headerlink" href="#cuda-gpu-compilation-model" title="Permalink to this heading">#</a></h1>
<div class="overview admonition">
<p class="admonition-title">Overview</p>
<p>Questions:</p>
<ul class="simple">
<li><p>What is NVCC compiler and why do we need it?</p></li>
<li><p>Can multiple GPU and CPU source code files be simultaneously compiled with NVCC?</p></li>
<li><p>How does NVCC distinguish between the host and device code domains and handle the compilation process?</p></li>
<li><p>How can runtime errors be handled during a CUDA program execution?</p></li>
</ul>
<p>Objectives:</p>
<ul class="simple">
<li><p>Understanding the basic mechanism of NVCC compilation phases</p></li>
<li><p>Learning about multiple source code compilation mode in NVCC compiler</p></li>
<li><p>Mastering the basics of error handling in a CUDA program using C/C++ wrapper marcos</p></li>
</ul>
</div>
<section id="nvidia-s-cuda-compiler">
<h2>1. NVIDIA’s CUDA Compiler<a class="headerlink" href="#nvidia-s-cuda-compiler" title="Permalink to this heading">#</a></h2>
<p><strong>NVIDIA’s CUDA compiler (NVCC)</strong> is distributed as part of CUDA Toolkit and
is based upon the poplar <a class="reference external" href="https://llvm.org/"><em>LLVM</em></a> open-source infrastructure.
Each CUDA program is a combination of host code written in C/C++ standard
semantics with some extensions within CUDA API as well as the GPU device
kernel functions. The nvcc compiler driver separates the host code from
that of the device. The host code is then pre-processed and compiled with
host’s <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#supported-host-compilers">C++ compilers supported by nvcc</a>.
The nvcc compiler also pre-processes and compiles the device kernel functions
using the proprietary NVIDIA assemblers and compilers. Then, nvcc embeds
the GPU kernels as <a class="reference external" href="https://en.wikipedia.org/wiki/Fat_binary"><em>fatbinary</em></a>
images into the host object files. Finally, during the linking stage, CUDA
runtime libraries are added for kernel procedure calls as well as memory and data
transfer managements. The description of the exact details of the
<a class="reference external" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#supported-phases">compilation phases</a>
is beyond the scope of this tutorial. The interested reader is referred to
<a class="reference external" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#introduction">CUDA Toolkit documentation</a>,
<a class="reference external" href="https://docs.nvidia.com/cuda/ptx-compiler-api/index.html"><em>parallel thread execution (PTX)</em> compiler API</a>
and <a class="reference external" href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html"><em>instruction set architecture (ISA)</em></a>
for further details.</p>
</section>
<section id="compiling-separate-source-files-using-nvcc">
<h2>2. Compiling Separate Source Files using NVCC<a class="headerlink" href="#compiling-separate-source-files-using-nvcc" title="Permalink to this heading">#</a></h2>
<p>In the [Summation of Arrays on GPUs]({{site.baseurl}}{% link _episodes/03-cuda-program-model.md %}#3-summation-of-arrays-on-gpus)
example, we criticized the length of the source code. Therefore,
we need to break it into smaller source files according to the
logical structure of our code.
Before CUDA 5.0, splitting the CUDA source code into separate files and
<a class="reference external" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#using-separate-compilation-in-cuda">multiple-source-file compilation</a>
was not possible and the only available option was the whole-code
compilation approach. Since we are using CUDA 11.2 here, this should
not be a problem anymore.
Let us now start breaking the code into separate source files by copying
the C <em>function signatures</em> and pasting them into an empty file. Name this
file as <em><strong>cCode.h</strong></em> and add the necessary include header pre-processor
directives and header guards to it. The resulting header file’s content
should be the same as the following code block</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-c" for="sd-tab-item-0">
C</label><div class="sd-tab-content docutils">
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*==================== cCode.h ===================*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#ifndef CCODE_H</span>
<span class="cp">#define CCODE_H</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;time.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sys/time.h&gt;</span>

<span class="cm">/*************************************************/</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="nf">chronometer</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">timezone</span><span class="w"> </span><span class="n">tzp</span><span class="p">;</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">timeval</span><span class="w"> </span><span class="n">tp</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gettimeofday</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tp</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">tzp</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="p">((</span><span class="kt">double</span><span class="p">)</span><span class="n">tp</span><span class="p">.</span><span class="n">tv_sec</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="kt">double</span><span class="p">)</span><span class="n">tp</span><span class="p">.</span><span class="n">tv_usec</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.</span><span class="n">e</span><span class="mi">-6</span><span class="p">);</span>
<span class="p">}</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">dataInitializer</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">inputArray</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">arraySumOnHost</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">arrayEqualityCheck</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>

<span class="cp">#endif </span><span class="c1">// CCODE_H</span>
</pre></div>
</div>
</div>
</div>
<p>Next, copy the C <em>function definitions</em> from the <em><strong>gpuVectorSum.cu</strong></em>
file to a new file, add the include pre-processor directives and save it
as <em><strong>cCode.c</strong></em>. The resulting source file should look like the following</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-1" name="sd-tab-set-1" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-c" for="sd-tab-item-1">
C</label><div class="sd-tab-content docutils">
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*==================== cCode.c ===================*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdbool.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cCode.h&quot;</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">dataInitializer</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">inputArray</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="cm">/* Generating float-type random numbers </span>
<span class="cm">     * between 0.0 and 1.0</span>
<span class="cm">     */</span>
<span class="w">    </span><span class="kt">time_t</span><span class="w"> </span><span class="n">t</span><span class="p">;</span>
<span class="w">    </span><span class="n">srand</span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="p">)</span><span class="w"> </span><span class="n">time</span><span class="p">(</span><span class="o">&amp;</span><span class="n">t</span><span class="p">)</span><span class="w"> </span><span class="p">);</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">inputArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">rand</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)(</span><span class="n">RAND_MAX</span><span class="p">)</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">arraySumOnHost</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">arrayEqualityCheck</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">tolerance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0E-8</span><span class="p">;</span>
<span class="w">    </span><span class="kt">bool</span><span class="w"> </span><span class="n">isEqual</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">abs</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">devicePtr</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">tolerance</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">isEqual</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">            </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Arrays are NOT equal because:</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">            </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;at %dth index: hostPtr[%d] = %5.2f \</span>
<span class="s">            and devicePtr[%d] = %5.2f;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span>\
<span class="w">            </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">hostPtr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">devicePtr</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">            </span><span class="k">break</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">isEqual</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Arrays are equal.</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>After moving all C-based functions into separate source and
header files, we should add the function declarations in
<em><strong>cCode.h</strong></em> to both <em><strong>cCode.c</strong></em> and <em><strong>gpuVectorSum.cu</strong></em> files.
The latter file now should contain the following code</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-2" name="sd-tab-set-2" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-cuda" for="sd-tab-item-2">
CUDA</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*================ gpuVectorSum.cu ===============*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cCode.h&quot;</span>

<span class="cm">/*-----------------------------------------------*/</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">arraySumOnDevice</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span>
<span class="w">        </span><span class="n">C</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
<span class="cm">/*************************************************/</span>
<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Kicking off %s</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>

<span class="w">    </span><span class="cm">/* Device setup */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">deviceIdx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">deviceIdx</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Device properties */</span>
<span class="w">    </span><span class="n">cudaDeviceProp</span><span class="w"> </span><span class="n">deviceProp</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceProp</span><span class="p">,</span><span class="w"> </span><span class="n">deviceIdx</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;GPU device %s with index (%d) is set!</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span>\
<span class="w">    </span><span class="n">deviceProp</span><span class="p">.</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">deviceIdx</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Fixing the vector size to 1 * 2^24 = 16777216 (64 MB) */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">vecSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="mi">24</span><span class="p">;</span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecSize</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Vector size: %d floats (%lu MB)</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Memory allocation on the host */</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">devicePtr</span><span class="p">;</span>
<span class="w">    </span><span class="n">h_A</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">h_B</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">hostPtr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">devicePtr</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">tStart</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">;</span>

<span class="w">    </span><span class="cm">/* Vector initialization on the host */</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">dataInitializer</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">dataInitializer</span><span class="p">(</span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for dataInitializer: %f second(s)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="w">    </span><span class="n">memset</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">memset</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">,</span><span class="w">  </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Vector summation on the host */</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">arraySumOnHost</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for arraySumOnHost: %f second(s)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* (Global) memory allocation on the device */</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_C</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Data transfer from host to device */</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Organizing grids and blocks */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">numThreadsInBlocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1024</span><span class="p">;</span>
<span class="w">    </span><span class="kt">dim3</span><span class="w"> </span><span class="nf">block</span><span class="w"> </span><span class="p">(</span><span class="n">numThreadsInBlocks</span><span class="p">);</span>
<span class="w">    </span><span class="kt">dim3</span><span class="w"> </span><span class="n">grid</span><span class="w">  </span><span class="p">((</span><span class="n">vecSize</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Execute the kernel from the host*/</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">arraySumOnDevice</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for arraySumOnDevice &lt;&lt;&lt; %d, %d &gt;&gt;&gt;: %f second(s)</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span>\
<span class="w">    </span><span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Returning the last error from a runtime call */</span>
<span class="w">    </span><span class="n">cudaGetLastError</span><span class="p">();</span>

<span class="w">    </span><span class="cm">/* Data transfer back from device to host */</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Check to see if the array summations on </span>
<span class="cm">     * CPU and GPU yield the same results </span>
<span class="cm">     */</span>
<span class="w">    </span><span class="n">arrayEqualityCheck</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Free the allocated memory on the device */</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_A</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_B</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_C</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Free the allocated memory on the host */</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">h_A</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">h_B</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">);</span>

<span class="w">    </span><span class="k">return</span><span class="p">(</span><span class="n">EXIT_SUCCESS</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s try to compile our multiple source files into an executable
using nvcc and run it using the following commands</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-3" name="sd-tab-set-3" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-shell" for="sd-tab-item-3">
SHELL</label><div class="sd-tab-content docutils">
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>nvcc<span class="w"> </span>gpuVectorSum.cu<span class="w"> </span>cCode.c<span class="w"> </span>-o<span class="w"> </span>gpuVectorSum
$<span class="w"> </span>./gpuVectorSum
</pre></div>
</div>
</div>
</div>
<p>After running the aforementioned commands, it is likely that you will get
some error messages like the following</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-4" name="sd-tab-set-4" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-error" for="sd-tab-item-4">
ERROR</label><div class="sd-tab-content docutils">
<div class="highlight-error notranslate"><div class="highlight"><pre><span></span>/tmp/tmpxft_000050f6_00000000-11_test.o: In function `main&#39;:
tmpxft_000050f6_00000000-6_test.cudafe1.cpp:(.text+0x16a): undefined reference to `dataInitializer(float*, int)&#39;
tmpxft_000050f6_00000000-6_test.cudafe1.cpp:(.text+0x181): undefined reference to `dataInitializer(float*, int)&#39;
tmpxft_000050f6_00000000-6_test.cudafe1.cpp:(.text+0x227): undefined reference to `arraySumOnHost(float*, float*, float*, int)&#39;
tmpxft_000050f6_00000000-6_test.cudafe1.cpp:(.text+0x477): undefined reference to `arrayEqualityCheck(float*, float*, int)&#39;
collect2: error: ld returned 1 exit status
</pre></div>
</div>
</div>
</div>
<p>The error comes from the <code class="docutils literal notranslate"><span class="pre">ld</span></code> (short for “load”) GNU linker which
complains about receiving undefined references to a list of functions
which we have put in <em><strong>cCode.c</strong></em> source file. Can you guess what is
the problem?</p>
<p>The main job of <code class="docutils literal notranslate"><span class="pre">ld</span></code> linker is to combine the object and archive files,
rearrange their data and manage their symbol references. Calling <code class="docutils literal notranslate"><span class="pre">ld</span></code>
is usually the last step of the compilation process. So, you can guess there
should not be any issues or bugs withing your code and it should be something
else. The source of the problem might not be that trivial to many of the
readers: nvcc compiler uses the host’s C++ compiler by default for compiling all
non-GPU code. Therefore, when you try to link the symbol references in
<em><strong>cCode.c</strong></em> file, the C++ compiler (and nvcc) do not know you that your are trying
to embed the C (not C++) function definitions in your program.</p>
<p>The solution to this problem is familiar to programmers who have experience
in calling C functions within C++ programs using the <code class="docutils literal notranslate"><span class="pre">extern</span> <span class="pre">&quot;C&quot;</span> <span class="pre">{</span> <span class="pre">...</span> <span class="pre">}</span></code>
snippet. By wrapping thin snippet around the <code class="docutils literal notranslate"><span class="pre">#include</span> <span class="pre">cCode.h</span></code> pre-processor
directive, you should be able to successfully compile your code using the
same command without any issues.</p>
<p>We have now, localized the C function definitions into their corresponding
implementation source files and headers. However, we still have a CUDA kernel
function definition left in the <em><strong>gpuVectorSum.cu</strong></em> file. Similar to what
we have done for C function definitions, CUDA kernel definitions can also be
moved to their pertinent source files. Therefore, the first step is to
create a header file, <em><strong>cudaCode.h</strong></em>, which should include the declaration
signature of the <code class="docutils literal notranslate"><span class="pre">arraySumOnDevice()</span></code> kernel function and look like
the following code block</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-5" name="sd-tab-set-5" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-cuda" for="sd-tab-item-5">
CUDA</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*================== cudaCode.h ==================*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#ifndef CUDACODE_H</span>
<span class="cp">#define CUDACODE_H</span>

<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">arraySumOnDevice</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>

<span class="cp">#endif </span><span class="c1">// CUDACODE_H</span>
</pre></div>
</div>
</div>
</div>
<p>Next, create a source file for kernel definition and save it as
<em><strong>cudaCode.cu</strong></em>. The contents of the <em><strong>cudaCode.cu</strong></em> file should be
the same as the following code block</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-6" name="sd-tab-set-6" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-cuda" for="sd-tab-item-6">
CUDA</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*================== cudaCode.cu =================*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cudaCode.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="cm">/*-----------------------------------------------*/</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">arraySumOnDevice</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span>
<span class="w">        </span><span class="n">C</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Do not forget to add the <em><strong>cudaCode.h</strong></em> pre-processor <code class="docutils literal notranslate"><span class="pre">#include</span></code> directive
in both <em><strong>cudaCode.cu</strong></em> and <em><strong>gpuVectorSum.cu</strong></em> files. The latter
file now does not include any function or kernel function definitions
for either host or device side code domains, respectively.
The <em><strong>gpuVectorSum.cu</strong></em> file now has the following structure</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-7" name="sd-tab-set-7" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-cuda" for="sd-tab-item-7">
CUDA</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*================ gpuVectorSum.cu ===============*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cudaCode.h&quot;</span>
<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cCode.h&quot;</span>
<span class="p">}</span>

<span class="cm">/*************************************************/</span>
<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Kicking off %s</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>

<span class="w">    </span><span class="cm">/* Device setup */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">deviceIdx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">deviceIdx</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Device properties */</span>
<span class="w">    </span><span class="n">cudaDeviceProp</span><span class="w"> </span><span class="n">deviceProp</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceProp</span><span class="p">,</span><span class="w"> </span><span class="n">deviceIdx</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;GPU device %s with index (%d) is set!</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span>\
<span class="w">    </span><span class="n">deviceProp</span><span class="p">.</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">deviceIdx</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Fixing the vector size to 1 * 2^24 = 16777216 (64 MB) */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">vecSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="mi">24</span><span class="p">;</span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecSize</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Vector size: %d floats (%lu MB)</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Memory allocation on the host */</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">devicePtr</span><span class="p">;</span>
<span class="w">    </span><span class="n">h_A</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">h_B</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">hostPtr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">devicePtr</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">tStart</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">;</span>

<span class="w">    </span><span class="cm">/* Vector initialization on the host */</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">dataInitializer</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">dataInitializer</span><span class="p">(</span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for dataInitializer: %f second(s)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="w">    </span><span class="n">memset</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">memset</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">,</span><span class="w">  </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Vector summation on the host */</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">arraySumOnHost</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for arraySumOnHost: %f second(s)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* (Global) memory allocation on the device */</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_C</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Data transfer from host to device */</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Organizing grids and blocks */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">numThreadsInBlocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1024</span><span class="p">;</span>
<span class="w">    </span><span class="kt">dim3</span><span class="w"> </span><span class="nf">block</span><span class="w"> </span><span class="p">(</span><span class="n">numThreadsInBlocks</span><span class="p">);</span>
<span class="w">    </span><span class="kt">dim3</span><span class="w"> </span><span class="n">grid</span><span class="w">  </span><span class="p">((</span><span class="n">vecSize</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Execute the kernel from the host*/</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">arraySumOnDevice</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for arraySumOnDevice &lt;&lt;&lt; %d, %d &gt;&gt;&gt;: %f second(s)</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span>\
<span class="w">    </span><span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Returning the last error from a runtime call */</span>
<span class="w">    </span><span class="n">cudaGetLastError</span><span class="p">();</span>

<span class="w">    </span><span class="cm">/* Data transfer back from device to host */</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Check to see if the array summations on </span>
<span class="cm">     * CPU and GPU yield the same results </span>
<span class="cm">     */</span>
<span class="w">    </span><span class="n">arrayEqualityCheck</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Free the allocated memory on the device */</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_A</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_B</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_C</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Free the allocated memory on the host */</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">h_A</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">h_B</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">);</span>

<span class="w">    </span><span class="k">return</span><span class="p">(</span><span class="n">EXIT_SUCCESS</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>The localization of each code domain into its own implementation source files
allows for regimenting a logical hierarchy within our package structure which
makes the debugging process more convenient and efficient as the pertinent
source files are now shorter as well.</p>
<p>In order to compile our code which now includes an additional source file,
we should run the following commands</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-8" name="sd-tab-set-8" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-shell" for="sd-tab-item-8">
SHELL</label><div class="sd-tab-content docutils">
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>nvcc<span class="w"> </span>gpuVectorSum.cu<span class="w"> </span>cCode.c<span class="w"> </span>cudaCode.cu<span class="w"> </span>-o<span class="w"> </span>gpuVectorSum
$<span class="w"> </span>./gpuVectorSum
</pre></div>
</div>
</div>
</div>
<p>There are still opportunities for us in the <code class="docutils literal notranslate"><span class="pre">main()</span></code> function within the
<em><strong>gpuVectorSum.cu</strong></em> file for further encapsulation of code into new functions
that can be subsequently transferred to the <em><strong>cCode.c</strong></em> or
<em><strong>cudaCode.cu</strong></em> source files and their corresponding headers.
The following exercise asks you to find these opportunities and
use them to make the code even shorter and therefore more readable and
easier to work with.</p>
<div class="exercise admonition">
<p class="admonition-title">Exercise</p>
<p>Parts of our code can still be made shorter through
encapsulation of groups of expressions and statements that can be
incorporated into a function. See if you can find these
code parts within the <em><strong>gpuVectorSum.cu</strong></em> file
and transfer them into <em><strong>cCode.c</strong></em> or
<em><strong>cudaCode.cu</strong></em> source files.</p>
<div class="solution dropdown admonition">
<p class="admonition-title">Solution</p>
<p>The three lines under <code class="docutils literal notranslate"><span class="pre">/*</span> <span class="pre">Device</span> <span class="pre">properties</span> <span class="pre">*/</span></code> comment
can be transferred into a function called <code class="docutils literal notranslate"><span class="pre">deviceProperties(deviceIdx)</span></code>
which takes the device index <code class="docutils literal notranslate"><span class="pre">deviceIdx</span></code> as its input argument.
So, the new <em><strong>cudaCode.cu</strong></em> file should take the following form</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-9" name="sd-tab-set-9" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-cuda" for="sd-tab-item-9">
CUDA</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*================== cudaCode.cu =================*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cudaCode.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="cm">/*-----------------------------------------------*/</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">arraySumOnDevice</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span>
<span class="w">        </span><span class="n">C</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="kr">__host__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">deviceProperties</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">deviceIdx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaDeviceProp</span><span class="w"> </span><span class="n">deviceProp</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceProp</span><span class="p">,</span><span class="w"> </span><span class="n">deviceIdx</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;GPU device %s with index (%d) is set!</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span>\
<span class="w">    </span><span class="n">deviceProp</span><span class="p">.</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">deviceIdx</span><span class="p">);</span><span class="w">   </span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>and the corresponding header file, <em><strong>cudaCode.h</strong></em>, should be
the same as the following code block</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-10" name="sd-tab-set-10" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-cuda" for="sd-tab-item-10">
CUDA</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*================== cudaCode.h ==================*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#ifndef CUDACODE_H</span>
<span class="cp">#define CUDACODE_H</span>

<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">arraySumOnDevice</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="kr">__host__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">deviceProperties</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">deviceIdx</span><span class="p">);</span>

<span class="cp">#endif </span><span class="c1">// CUDACODE_H</span>
</pre></div>
</div>
</div>
</div>
<p>Note that we have used <code class="docutils literal notranslate"><span class="pre">__host__</span></code> declaration expression qualifier
for our device function, <code class="docutils literal notranslate"><span class="pre">deviceProperties()</span></code>, since it will run from
host and therefore, no specific memory management on the device will
required.
With the aforementioned changes, the <em><strong>gpuVectorSum.cu</strong></em> file
takes the following form</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-11" name="sd-tab-set-11" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-cuda" for="sd-tab-item-11">
CUDA</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*================ gpuVectorSum.cu ===============*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cudaCode.h&quot;</span>
<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cCode.h&quot;</span>
<span class="p">}</span>

<span class="cm">/*************************************************/</span>
<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Kicking off %s</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>

<span class="w">    </span><span class="cm">/* Device setup */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">deviceIdx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">deviceIdx</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Device properties */</span>
<span class="w">    </span><span class="n">deviceProperties</span><span class="p">(</span><span class="n">deviceIdx</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Fixing the vector size to 1 * 2^24 = 16777216 (64 MB) */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">vecSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="mi">24</span><span class="p">;</span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecSize</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Vector size: %d floats (%lu MB)</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Memory allocation on the host */</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">devicePtr</span><span class="p">;</span>
<span class="w">    </span><span class="n">h_A</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">h_B</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">hostPtr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">devicePtr</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">tStart</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">;</span>

<span class="w">    </span><span class="cm">/* Vector initialization on the host */</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">dataInitializer</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">dataInitializer</span><span class="p">(</span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for dataInitializer: %f second(s)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="w">    </span><span class="n">memset</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">memset</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">,</span><span class="w">  </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Vector summation on the host */</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">arraySumOnHost</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for arraySumOnHost: %f second(s)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* (Global) memory allocation on the device */</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_C</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Data transfer from host to device */</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Organizing grids and blocks */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">numThreadsInBlocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1024</span><span class="p">;</span>
<span class="w">    </span><span class="kt">dim3</span><span class="w"> </span><span class="nf">block</span><span class="w"> </span><span class="p">(</span><span class="n">numThreadsInBlocks</span><span class="p">);</span>
<span class="w">    </span><span class="kt">dim3</span><span class="w"> </span><span class="n">grid</span><span class="w">  </span><span class="p">((</span><span class="n">vecSize</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Execute the kernel from the host*/</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">arraySumOnDevice</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for arraySumOnDevice &lt;&lt;&lt; %d, %d &gt;&gt;&gt;: %f second(s) </span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span>\
<span class="w">    </span><span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Returning the last error from a runtime call */</span>
<span class="w">    </span><span class="n">cudaGetLastError</span><span class="p">();</span>

<span class="w">    </span><span class="cm">/* Data transfer back from device to host */</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Check to see if the array summations on </span>
<span class="cm">     * CPU and GPU yield the same results </span>
<span class="cm">     */</span>
<span class="w">    </span><span class="n">arrayEqualityCheck</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Free the allocated memory on the device */</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_A</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_B</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_C</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Free the allocated memory on the host */</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">h_A</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">h_B</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">);</span>

<span class="w">    </span><span class="k">return</span><span class="p">(</span><span class="n">EXIT_SUCCESS</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="error-handling">
<h2>3. Error Handling<a class="headerlink" href="#error-handling" title="Permalink to this heading">#</a></h2>
<p>Many of the CUDA function calls within each CUDA program are asynchronous–
the execution flow returns to the host immediately after the function call.
The asynchronous nature of these function calls makes it difficult to identify
and troubleshoot the source of errors if several CUDA functions have been
called consecutively. Fortunately, with the exception of kernel executions,
CUDA functions return error codes of <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6"><code class="docutils literal notranslate"><span class="pre">cudaError_t</span></code></a>
enumerated type. As such, we can define error handling macros to wrap
around the CUDA function calls and check them for any possible errors.</p>
<p>In order to include a macro definition within our
[Summation of Arrays on GPUs]({{site.baseurl}}{% link _episodes/03-cuda-program-model.md %}#3-summation-of-arrays-on-gpus)
code, open the <em><strong>cCode.h</strong></em> header file and add the following macro definition to it</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-12" name="sd-tab-set-12" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-cuda" for="sd-tab-item-12">
CUDA</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*==================== cCode.h ===================*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#ifndef CCODE_H</span>
<span class="cp">#define CCODE_H</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;time.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sys/time.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span>

<span class="cp">#define ERRORHANDLER(funcCall) { \</span>
<span class="cp">    const cudaError_t error = funcCall; \</span>
<span class="cp">    const char *errorMessage = cudaGetErrorString(error); \</span>
<span class="cp">    if (error != cudaSuccess) { \</span>
<span class="cp">        printf(&quot;Error in file %s, line %d, code %d,  Message %s\n&quot;, \</span>
<span class="cp">        __FILE__, __LINE__, error, errorMessage); \</span>
<span class="cp">        exit(EXIT_FAILURE); \</span>
<span class="cp">    } \</span>
<span class="cp">}</span>
<span class="cm">/*************************************************/</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="nf">chronometer</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">timezone</span><span class="w"> </span><span class="n">tzp</span><span class="p">;</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">timeval</span><span class="w"> </span><span class="n">tp</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gettimeofday</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tp</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">tzp</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="p">((</span><span class="kt">double</span><span class="p">)</span><span class="n">tp</span><span class="p">.</span><span class="n">tv_sec</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="kt">double</span><span class="p">)</span><span class="n">tp</span><span class="p">.</span><span class="n">tv_usec</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.</span><span class="n">e</span><span class="mi">-6</span><span class="p">);</span>
<span class="p">}</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">dataInitializer</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">inputArray</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">arraySumOnHost</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">arrayEqualityCheck</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>

<span class="cp">#endif </span><span class="c1">// CCODE_H</span>
</pre></div>
</div>
</div>
</div>
<p>Note that backslashes (<code class="docutils literal notranslate"><span class="pre">\</span></code>) are used as the
<em>line continuation escape character</em> since marcos should be defined
in one line. Each backslash must be the last character on the line
otherwise you will get an error.
We can now wrap our CUDA function calls within <code class="docutils literal notranslate"><span class="pre">ERRORHANDLER()</span></code> macro
in order to capture the errors. If an error happens, <code class="docutils literal notranslate"><span class="pre">ERRORHANDLER()</span></code>
macro prints the error code in a human-readable format and terminates
the program by calling the <code class="docutils literal notranslate"><span class="pre">exit(EXIT_FAILURE)</span></code> function.</p>
<div class="exercise admonition">
<p class="admonition-title">Exercise</p>
<p>Try to wrap every CUDA function call in <em><strong>gpuVectorSum.cu</strong></em> file
with the <code class="docutils literal notranslate"><span class="pre">ERRORHANDLER()</span></code> macro.</p>
<div class="solution dropdown admonition">
<p class="admonition-title">Solution</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-13" name="sd-tab-set-13" type="radio">
</input><label class="sd-tab-label" data-sync-id="tabcode-cuda" for="sd-tab-item-13">
CUDA</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="cm">/*================================================*/</span>
<span class="cm">/*================ gpuVectorSum.cu ===============*/</span>
<span class="cm">/*================================================*/</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cudaCode.h&quot;</span>
<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cCode.h&quot;</span>
<span class="p">}</span>

<span class="cm">/*************************************************/</span>
<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">**</span><span class="n">argv</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Kicking off %s</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>

<span class="w">    </span><span class="cm">/* Device setup */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">deviceIdx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">deviceIdx</span><span class="p">));</span>

<span class="w">    </span><span class="cm">/* Device properties */</span>
<span class="w">    </span><span class="n">deviceProperties</span><span class="p">(</span><span class="n">deviceIdx</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Fixing the vector size to 1 * 2^24 = 16777216 (64 MB) */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">vecSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="mi">24</span><span class="p">;</span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vecSize</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Vector size: %d floats (%lu MB)</span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="o">/</span><span class="mi">1024</span><span class="o">/</span><span class="mi">1024</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Memory allocation on the host */</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">devicePtr</span><span class="p">;</span>
<span class="w">    </span><span class="n">h_A</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">h_B</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">hostPtr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">devicePtr</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">tStart</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">;</span>

<span class="w">    </span><span class="cm">/* Vector initialization on the host */</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">dataInitializer</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">dataInitializer</span><span class="p">(</span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for dataInitializer: %f second(s)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="w">    </span><span class="n">memset</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>
<span class="w">    </span><span class="n">memset</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">,</span><span class="w">  </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Vector summation on the host */</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">arraySumOnHost</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for arraySumOnHost: %f second(s)</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* (Global) memory allocation on the device */</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_C</span><span class="p">;</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">));</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">));</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">));</span>

<span class="w">    </span><span class="cm">/* Data transfer from host to device */</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">h_A</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">));</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">h_B</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">));</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">));</span>

<span class="w">    </span><span class="cm">/* Organizing grids and blocks */</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">numThreadsInBlocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1024</span><span class="p">;</span>
<span class="w">    </span><span class="kt">dim3</span><span class="w"> </span><span class="nf">block</span><span class="w"> </span><span class="p">(</span><span class="n">numThreadsInBlocks</span><span class="p">);</span>
<span class="w">    </span><span class="kt">dim3</span><span class="w"> </span><span class="n">grid</span><span class="w">  </span><span class="p">((</span><span class="n">vecSize</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* Execute the kernel from the host*/</span>
<span class="w">    </span><span class="n">tStart</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">();</span>
<span class="w">    </span><span class="n">arraySumOnDevice</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span><span class="w"> </span><span class="n">d_B</span><span class="p">,</span><span class="w"> </span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaDeviceSynchronize</span><span class="p">());</span>
<span class="w">    </span><span class="n">tElapsed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chronometer</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tStart</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Elapsed time for arraySumOnDevice &lt;&lt;&lt; %d, %d &gt;&gt;&gt;: %f second(s) </span><span class="se">\n\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span>\
<span class="w">    </span><span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">tElapsed</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Returning the last error from a runtime call */</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaGetLastError</span><span class="p">());</span>

<span class="w">    </span><span class="cm">/* Data transfer back from device to host */</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">d_C</span><span class="p">,</span><span class="w"> </span><span class="n">vecSizeInBytes</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">));</span>

<span class="w">    </span><span class="cm">/* Check to see if the array summations on </span>
<span class="cm">     * CPU and GPU yield the same results </span>
<span class="cm">     */</span>
<span class="w">    </span><span class="n">arrayEqualityCheck</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">,</span><span class="w"> </span><span class="n">devicePtr</span><span class="p">,</span><span class="w"> </span><span class="n">vecSize</span><span class="p">);</span>
<span class="cm">/*-----------------------------------------------*/</span>
<span class="w">    </span><span class="cm">/* Free the allocated memory on the device */</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_A</span><span class="p">));</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_B</span><span class="p">));</span>
<span class="w">    </span><span class="n">ERRORHANDLER</span><span class="p">(</span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_C</span><span class="p">));</span>

<span class="w">    </span><span class="cm">/* Free the allocated memory on the host */</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">h_A</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">h_B</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">hostPtr</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">devicePtr</span><span class="p">);</span>

<span class="w">    </span><span class="k">return</span><span class="p">(</span><span class="n">EXIT_SUCCESS</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>We should point out that our <code class="docutils literal notranslate"><span class="pre">deviceProperties()</span></code> function is not
a CUDA API function. Since it encapsulates the <code class="docutils literal notranslate"><span class="pre">cudaGetDeviceProperties()</span></code>
CUDA function within its implementation, we could wrap the
<code class="docutils literal notranslate"><span class="pre">ERRORHANDLER()</span></code>macro directly around it within the <code class="docutils literal notranslate"><span class="pre">deviceProperties()</span></code>
function definition. However, this will add a C-based header file within
our device-based code which is in contradiction with our first intention
of separating the device and the host side code domains within different source
files. This is one of those situations that we might have to compromise
somehow– either by adding the <em><strong>cCode.h</strong></em> header into our
<em><strong>cudaCode.cu</strong></em> file or leaving the <code class="docutils literal notranslate"><span class="pre">cudaGetDeviceProperties()</span></code>
CUDA function un-encapsulated within the <code class="docutils literal notranslate"><span class="pre">main()</span></code> function.</p>
</div>
</div>
<div class="key admonition">
<p class="admonition-title">Key Points</p>
<ul class="simple">
<li><p>The NVCC compiler</p></li>
<li><p>Compilation phases</p></li>
<li><p>Compiling multiple CPU and GPU source code files simultaneously</p></li>
<li><p>Error handling in a CUDA program</p></li>
</ul>
</div>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="03-cuda-program-model.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">CUDA Programming Model</p>
      </div>
    </a>
    <a class="right-next"
       href="05-cuda-execution-model.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">CUDA Execution Model</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nvidia-s-cuda-compiler">1. NVIDIA’s CUDA Compiler</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compiling-separate-source-files-using-nvcc">2. Compiling Separate Source Files using NVCC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-handling">3. Error Handling</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="_sources/04-gpu-compilation-model.md.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner"></div>
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  



  
  
  
  
  
  
  


<div class="row h-10">
    <div class="col-2">
        <a href="https://molssi.org/" target="_blank" title="Go to MolSSI in a new tab">
            <img src="_static/molssi_main_logo.png" class="logo__image only-light footer_logo" alt="Logo image">
            <img src="_static/molssi_main_logo_inverted_white.png" class="logo__image only-dark footer_logo" alt="Logo image">
        </a>
    </div>
    <div class="col-8">
        <p> &copy; Copyright 2019-2023 <a href="https://molssi.org/">The Molecular Sciences Software Institute</a></p>
        <p>Funded by the National Science Foundation 
          <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=1547580">OAC-1547580</a> and 
          <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2136142">CHE-2136142.</a></p>
 
        
        <p class="sphinx-version">
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.3.0.<br>
        </p>
        

        <p class="theme-version">
        Built with a customized <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.1.
        </p>

    </div>
    <div class="col-2">
        <a href="https://nsf.gov/" target="_blank" title="Go to the NSF in a new tab">
            <img src="_static/nsf.png" class="footer_logo" alt="The NSF">
          </a>
    </div>
</div></div>
      
    </div>
  
  
</div>

  </footer>
  </body>
</html>